#option 1 part A -- I wrote this with help of error-prone youtube video. More flexible
def compute_tp_fp_fn_tn(truth, test, define_population=1):
    '''
    defines tp_fp_fn_tn without sklearn library
    True positive - truth = 1, test = 1
    False positive - truth = 0, test = 1
    False negative - truth = 1, test = 0
    True negative - truth = 0, test = 0
    use define_population to narrow population to rows with >0 in define_population series  
    '''
    tp = sum((truth == 1) & (test == 1) & (define_population > 0))
    fp = sum((truth == 0) & (test == 1) & (define_population > 0))
    fn = sum((truth == 1) & (test == 0) & (define_population > 0))
    tn = sum((truth == 0) & (test == 0) & (define_population > 0))
    return tp, fp, fn, tn
    
#option 1 part B    
def test_char(truth,test,define_population=1):
    '''
    prints sensitivity and specificity for a series 'test' based on a series 'truth'
    use 'define_population' to narrow population to include only rows with >0 from define_population series  
    default define_population = 1 includes all rows from 'truth' and 'test'
    does not require sklearn library
    '''
    print('The sensitivity and specificity for {}, respectively, :'.format(test.name))
    tp, fp, fn, tn = compute_tp_fp_fn_tn(truth, test, define_population)
    SN = tp/(tp+fn)
    SP = tn/(tn+fp)
    return SN, SP
    
#option 2    
def test_char1(truth, test):
    '''
    requires 'from sklearn.metrics import confusion_matrix'
    prints sensitivity and specificity for a 'test' based on 'truth' 
    '''
    print('The sensitivity and specificity for {}, respectively, :'.format(test.name))
    tn, fp, fn, tp = confusion_matrix(truth, test).ravel()
        #unclear why tn, fp, fn, tp is the paradigm for sklearn confusion matrix
    SN = tp/(tp+fn)
    SP = tn/(tn+fp)
    return SN, SP
